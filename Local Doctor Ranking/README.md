# Local Doctor Ranking Server

A local web server that provides doctor ranking functionality using the parallel ranking algorithm and your merged doctor data.

## Features

- üöÄ **Fast**: Data loaded once at startup, served efficiently
- üîç **Smart Ranking**: Uses parallel AI processing and two-stage BM25 retrieval
- ‚ö° **Specialty Filtering**: Automatically filters by specialty before ranking (7-30x faster!)
- üìä **Large Dataset**: Handles 11,895+ doctor records efficiently
- üåê **Web UI**: Beautiful, modern interface for searching doctors
- üîå **REST API**: Simple API endpoints for integration

## Quick Start

### 1. Install Dependencies

```bash
npm install
```

### 2. Configure Environment

Make sure your `.env` file in `parallel-ranking-package/` folder has your OpenAI API key:

```
OPENAI_API_KEY=sk-your-actual-key-here
```

### 3. Start the Server

```bash
npm start
```

The server will:
- Load all doctor data from `merged_all_sources_20260124_150256.json`
- Start on `http://localhost:3000`
- Display statistics and ready status

### 4. Use the Web Interface

Open your browser and go to:
```
http://localhost:3000
```

You'll see a search interface where you can:
- Enter queries like "I need SVT ablation"
- See ranked results with scores
- View doctor details, specialties, and GMC numbers

## API Endpoints

### GET /api/health
Health check endpoint

**Response:**
```json
{
  "status": "ok",
  "dataLoaded": true,
  "totalPractitioners": 11895,
  "loadTime": 1234
}
```

### GET /api/stats
Get data statistics

**Response:**
```json
{
  "success": true,
  "stats": {
    "total": 11895,
    "withGMC": 11398,
    "uniqueSpecialties": 124,
    ...
  }
}
```

### POST /api/rank
Rank doctors by query

**Request:**
```json
{
  "query": "I need SVT ablation",
  "messages": [],  // optional conversation history
  "location": null,  // optional location filter
  "specialty": null,  // optional manual specialty filter (e.g., "Cardiology")
  "shortlistSize": 10  // optional, default 10
}
```

**Note:** The server automatically filters by specialty/subspecialty based on query intent to optimize performance. You can also manually specify a specialty filter.

**Response:**
```json
{
  "success": true,
  "query": "I need SVT ablation",
  "totalResults": 10,
  "results": [
    {
      "rank": 1,
      "name": "Dr. John Smith",
      "title": "Consultant Cardiologist",
      "specialty": "Cardiology",
      "subspecialties": ["Electrophysiology"],
      "score": 99.52,
      "bm25Score": 63.45,
      "gmc_number": "1234567",
      ...
    }
  ],
  "queryInfo": {
    "q_patient": "I need SVT ablation",
    "intent_terms": ["supraventricular tachycardia", ...],
    "goal": "procedure_intervention",
    "specificity": "named_procedure",
    "confidence": 0.9
  },
  "processingTime": {
    "sessionContext": 1234,
    "ranking": 567,
    "total": 1801
  }
}
```

### GET /api/search?q=query
Simple search endpoint (GET method)

**Example:**
```
GET /api/search?q=I%20need%20SVT%20ablation&limit=10
```

## Example Queries

Try these example queries:

- **Specific Procedure**: "I need SVT ablation"
- **Symptom-based**: "I have chest pain"
- **Specialty-specific**: "Looking for a cardiologist for atrial fibrillation"
- **General**: "I need a general surgeon for hernia repair"

## How It Works

1. **Data Loading**: On startup, the server loads all 11,895 doctor records from your merged data file and transforms them into the format expected by the ranking algorithm.

2. **Query Processing**: When you submit a query:
   - The parallel ranking algorithm analyzes your query using AI
   - Extracts intent terms, anchor phrases, and determines query clarity
   - Classifies goal (diagnostic_workup, procedure_intervention, etc.) and specificity
   - **Infers likely subspecialties** (e.g., "SVT ablation" ‚Üí "Electrophysiology")

3. **Specialty Filtering** (Performance Optimization):
   - Before ranking, practitioners are filtered by inferred subspecialties
   - This dramatically reduces the dataset size (e.g., from 11,895 to ~200-500 relevant doctors)
   - Speeds up ranking by 5-10x while maintaining accuracy
   - Falls back to full dataset if filtering is too aggressive

4. **Two-Stage Ranking**:
   - **Stage A**: BM25 retrieval using clean patient query (top 50 candidates from filtered set)
   - **Stage B**: Rescoring with intent terms, anchor phrases, and negative keywords

5. **Results**: Top ranked doctors are returned with detailed scoring information and filtering stats

## Performance

- **Initial Load**: ~2-5 seconds (one-time, on startup)
- **Query Processing**: ~1-3 seconds per query
  - **With Specialty Filtering**: Typically searches 200-500 doctors instead of 11,895
  - **Speed Improvement**: 5-10x faster ranking while maintaining accuracy
- **Memory Usage**: ~200-500MB (depending on data size)

### Specialty Filtering Benefits

- **Reduced Search Space**: Instead of ranking all 11,895 doctors, the system filters to relevant specialties first
- **Faster Results**: BM25 ranking on 200-500 doctors is much faster than on 11,895
- **Maintained Accuracy**: AI-inferred subspecialties ensure relevant doctors aren't filtered out
- **Smart Fallback**: If filtering is too aggressive (<10 results), falls back to full dataset

## File Structure

```
.
‚îú‚îÄ‚îÄ server.js              # Main server file
‚îú‚îÄ‚îÄ apply-ranking.js       # Ranking logic and data transformation
‚îú‚îÄ‚îÄ public/
‚îÇ   ‚îî‚îÄ‚îÄ index.html         # Web UI
‚îú‚îÄ‚îÄ merged_all_sources_20260124_150256.json  # Doctor data
‚îî‚îÄ‚îÄ parallel-ranking-package/  # Ranking algorithm package
```

## Troubleshooting

**Server won't start:**
- Check that `merged_all_sources_20260124_150256.json` exists in the project root
- Verify OpenAI API key is set in `parallel-ranking-package/.env`
- Check port 3000 is not already in use

**No results or poor rankings:**
- Try making your query more specific
- Include explicit procedure names or conditions
- Check the query info in the response to see how it was interpreted

**Slow performance:**
- Initial load takes time (one-time cost)
- Query processing uses AI, so it takes 1-3 seconds
- Consider increasing `shortlistSize` for more results (but slower)

## Development

To modify the server:

1. Edit `server.js` for API endpoints
2. Edit `public/index.html` for UI changes
3. Edit `apply-ranking.js` for ranking logic changes

Restart the server after changes:
```bash
# Stop: Ctrl+C
# Start: npm start
```

## License

ISC
